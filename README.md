<img src="asset/image/banner.png" alt="Alphora æ¡†æ¶ banner" style="max-width: 50%; height: auto;">

# Alphora: ä¸€ä¸ªè½»é‡çš„æ™ºèƒ½ä½“å¼€å‘æ¡†æ¶

<div align="center">
  <br>
  <br>
  
  [![Python Version](https://img.shields.io/badge/Python-3.9%2B-blue)](https://www.python.org/)
  [![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)
  [![Latest Release](https://img.shields.io/badge/Release-v0.1.0-orange)](https://github.com/your-username/alphora/releases)

  <a href="README.en.md">ğŸŒ English Version</a>
</div>

## ğŸŒŸ æ ¸å¿ƒç‰¹æ€§

- **çµæ´»çš„æ™ºèƒ½ä½“æ¶æ„**ï¼šåŸºäº `BaseAgent` ç±»æ„å»ºï¼Œæ”¯æŒæ´¾ç”Ÿã€ç»„åˆå’ŒåŠ¨æ€åˆ›å»º
- **å¤šæ¨¡å‹æ”¯æŒ**ï¼šå…¼å®¹ OpenAI ç±» APIï¼Œæ”¯æŒå¤šæ¨¡å‹è´Ÿè½½å‡è¡¡å’ŒåŠ¨æ€é€‰æ‹©
- **æ™ºèƒ½è®°å¿†ç®¡ç†**ï¼šå†…ç½®è®°å¿†æ± ï¼Œæ”¯æŒçŸ­æœŸ/é•¿æœŸè®°å¿†ï¼Œè‡ªåŠ¨æ¸…ç†å’Œä¼˜å…ˆçº§æ’åº
- **é«˜çº§æç¤ºè¯ç³»ç»Ÿ**ï¼šæ”¯æŒ Jinja2 æ¨¡æ¿ã€å ä½ç¬¦æ›¿æ¢å’Œå¹¶è¡Œå¤„ç†
- **å¼ºå¤§åå¤„ç†**ï¼šæä¾› JSON æå–ã€ç±»å‹è½¬æ¢ã€æ¨¡å¼åŒ¹é…ç­‰å¤šç§åå¤„ç†å·¥å…·
- **å¿«é€Ÿ API éƒ¨ç½²**ï¼šä¸€é”®å‘å¸ƒä¸º RESTful APIï¼Œæ”¯æŒ OpenAI å…¼å®¹æ¥å£
- **æµå¼è¾“å‡º**ï¼šæ”¯æŒå®æ—¶æµå¼å“åº”å’Œè‡ªå®šä¹‰æµå†…å®¹ç±»å‹

## ğŸ“¦ å®‰è£…

### ç¯å¢ƒè¦æ±‚
- Python >= 3.9
- pip >= 21.0

### å®‰è£…æ–¹å¼

#### ä½¿ç”¨ pip å®‰è£…ï¼ˆæ¨èï¼‰
```bash
pip install alphora
```

#### ä»æºç å®‰è£…
```bash
git clone https://github.com/your-username/alphora.git
cd alphora
pip install -e .
```

### æ ¸å¿ƒä¾èµ–
| ä¾èµ–åŒ… | ç‰ˆæœ¬è¦æ±‚ | åŠŸèƒ½è¯´æ˜ |
|--------|----------|----------|
| dill | 0.3.9 | å¯¹è±¡åºåˆ—åŒ– |
| fastapi | 0.128.0 | API æœåŠ¡æ„å»º |
| Jinja2 | 3.1.6 | æç¤ºè¯æ¨¡æ¿å¼•æ“ |
| json_repair | 0.52.1 | JSON æ•°æ®ä¿®å¤ |
| openai | 2.14.0 | LLM æ¨¡å‹è°ƒç”¨ |
| pandas | 2.3.3 | æ•°æ®å¤„ç† |
| pydantic | 2.12.5 | æ•°æ®éªŒè¯ |
| Requests | 2.32.5 | HTTP è¯·æ±‚ |
| uvicorn | 0.40.0 | ASGI æœåŠ¡å™¨ |



### å®‰è£…æ­¥éª¤

```bash
# ä»æºä»£ç å®‰è£…
git clone <repository-url>
cd alphora
pip install -e .
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. åˆ›å»ºä¸€ä¸ªç®€å•çš„æ™ºèƒ½ä½“

```python
from alphora.agent.base_agent import BaseAgent
from alphora.models.llms.openai_like import OpenAILike

# é…ç½® LLM
llm = OpenAILike(
  api_key="your-api-key",
  base_url="https://api.example.com/v1",
  model_name="your-model-name"
)

# åˆ›å»ºæ™ºèƒ½ä½“
agent = BaseAgent(llm=llm, verbose=True)

# åˆ›å»ºæç¤ºè¯
prompt = agent.create_prompt(prompt="ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ï¼Œè¯·å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š{{query}}")


# è°ƒç”¨æ™ºèƒ½ä½“
async def main():
  response = await prompt.acall(query="ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ", is_stream=False)
  print(response)


if __name__ == "__main__":
  import asyncio

  asyncio.run(main())
```

### 2. åˆ›å»ºè‡ªå®šä¹‰æ™ºèƒ½ä½“

```python
from alphora.agent.base_agent import BaseAgent
from alphora.models.llms.openai_like import OpenAILike
from alphora.server.openai_request_body import OpenAIRequest


class TeacherAgent(BaseAgent):
  async def teacher(self, query):
    # æ„å»ºå†å²å¯¹è¯
    history = self.memory.build_history()

    # åˆ›å»ºæç¤ºè¯
    prompt = self.create_prompt(
      prompt="ä½ æ˜¯ä¸€ä¸ªå¤§å­¦æ•°å­¦è€å¸ˆï¼Œç›®å‰æ­£åœ¨å›å¤å­¦ç”Ÿçš„é—®é¢˜ï¼Œè¯·ä½ å‡†ç¡®çš„å›å¤å­¦ç”Ÿçš„é—®é¢˜ã€‚\n\nå†å²å¯¹è¯: \n{{history}} \n\nå­¦ç”Ÿè¯´:{{query}}"
    )

    prompt.update_placeholder(history=history)

    # è°ƒç”¨ LLM
    response = await prompt.acall(query=query, is_stream=False)

    # ä¿å­˜å¯¹è¯è®°å¿†
    self.memory.add_memory(role='å­¦ç”Ÿ', content=query)
    self.memory.add_memory(role='è€å¸ˆ', content=response)

    return response

  async def api_logic(self, request: OpenAIRequest):
    query = request.get_user_query()
    response = await self.teacher(query)
    return response
```

### 3. éƒ¨ç½²ä¸º API æœåŠ¡

```python
import uvicorn
from alphora.server.quick_api import publish_agent_api, APIPublisherConfig

# åˆ›å»ºæ™ºèƒ½ä½“å®ä¾‹
agent = TeacherAgent(llm=llm)

# é…ç½® API å‘å¸ƒ
config = APIPublisherConfig(
    memory_ttl=7200,  # è®°å¿†æœ‰æ•ˆæœŸï¼ˆç§’ï¼‰
    max_memory_items=2000,  # æœ€å¤§è®°å¿†æ¡ç›®æ•°
    auto_clean_interval=300,  # è‡ªåŠ¨æ¸…ç†é—´éš”ï¼ˆç§’ï¼‰
    api_title="Teacher Agent API Service",
    api_description="å¤§å­¦æ•°å­¦è€å¸ˆæ™ºèƒ½ä½“ API"
)

# å‘å¸ƒ API
app = publish_agent_api(
    agent=agent,
    method="api_logic",
    config=config
)

# å¯åŠ¨æœåŠ¡å™¨
if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

## ğŸ—ï¸ é¡¹ç›®æ¶æ„

Alphoraé‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œå„ç»„ä»¶æ¾è€¦åˆï¼Œæ˜“äºæ‰©å±•å’Œç»´æŠ¤ã€‚

### ç›®å½•ç»“æ„

```
alphora/
â”œâ”€â”€ agent/           # æ™ºèƒ½ä½“æ ¸å¿ƒæ¨¡å—
â”œâ”€â”€ memory/          # è®°å¿†ç®¡ç†ç³»ç»Ÿ
â”œâ”€â”€ models/          # æ¨¡å‹æ¥å£å±‚
â”œâ”€â”€ postprocess/     # åå¤„ç†æ¨¡å—
â”œâ”€â”€ prompter/        # æç¤ºè¯ç³»ç»Ÿ
â”œâ”€â”€ sandbox/         # æ²™ç›’ç¯å¢ƒ
â”œâ”€â”€ server/          # æœåŠ¡å™¨åŠŸèƒ½
â””â”€â”€ utils/           # å·¥å…·å‡½æ•°
```

### æ ¸å¿ƒæ¨¡å—å…³ç³»

1. **æ™ºèƒ½ä½“å±‚**ï¼šæ¡†æ¶æ ¸å¿ƒï¼Œåè°ƒå„æ¨¡å—å·¥ä½œ
2. **æ¨¡å‹å±‚**ï¼šä¸å„ç§ LLM æ¨¡å‹äº¤äº’
3. **æç¤ºè¯å±‚**ï¼šç®¡ç†å’Œæ¸²æŸ“æç¤ºè¯æ¨¡æ¿
4. **è®°å¿†å±‚**ï¼šå­˜å‚¨å’Œç®¡ç†å¯¹è¯å†å²
5. **åå¤„ç†å±‚**ï¼šå¤„ç†æ¨¡å‹å“åº”
6. **æœåŠ¡å™¨å±‚**ï¼šæä¾› API éƒ¨ç½²èƒ½åŠ›

## ğŸ§© æ ¸å¿ƒæ¨¡å—

### 1. Agentï¼ˆæ™ºèƒ½ä½“ï¼‰
æ™ºèƒ½ä½“æ˜¯æ¡†æ¶çš„æ ¸å¿ƒç»„ä»¶ï¼Œè´Ÿè´£åè°ƒå„ä¸ªæ¨¡å—çš„å·¥ä½œã€‚`BaseAgent` æä¾›äº†æ¨¡å‹ç®¡ç†ã€è®°å¿†ç®¡ç†ã€æç¤ºè¯åˆ›å»ºã€æ™ºèƒ½ä½“æ´¾ç”Ÿã€æµå¼å¤„ç†å’Œå¹¶è¡Œå¤„ç†ç­‰åŠŸèƒ½ã€‚

```python
# æ™ºèƒ½ä½“æ´¾ç”Ÿç¤ºä¾‹
parent_agent = BaseAgent(llm=parent_llm)
child_agent = parent_agent.derive(CustomAgent, additional_param="value")
```

### 2. Memoryï¼ˆè®°å¿†ï¼‰
è®°å¿†æ¨¡å—è´Ÿè´£ç®¡ç†æ™ºèƒ½ä½“çš„å¯¹è¯å†å²å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ”¯æŒçŸ­æœŸ/é•¿æœŸè®°å¿†ã€è®°å¿†æ± ç®¡ç†ã€è‡ªåŠ¨æ¸…ç†å’Œä¼˜å…ˆçº§æ’åºã€‚

```python
# è®°å¿†ä½¿ç”¨ç¤ºä¾‹
history = agent.memory.build_history(memory_id="default", max_round=5)
agent.memory.add_memory(role="ç”¨æˆ·", content="ä½ å¥½", score=0.8)
memories = agent.memory.get_top_memories(memory_id="default", top_n=3)
```

### 3. Prompterï¼ˆæç¤ºè¯ï¼‰
æç¤ºè¯æ¨¡å—è´Ÿè´£ç®¡ç†å’Œæ¸²æŸ“æç¤ºè¯æ¨¡æ¿ï¼Œæ”¯æŒä»æ–‡ä»¶æˆ–å­—ç¬¦ä¸²åŠ è½½æ¨¡æ¿ã€Jinja2 è¯­æ³•ã€å ä½ç¬¦æ›¿æ¢å’Œå¹¶è¡Œå¤„ç†ã€‚

```python
# æç¤ºè¯ä½¿ç”¨ç¤ºä¾‹
prompt = agent.create_prompt("ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ï¼Œè¯·å›ç­”ï¼š{{query}}")
prompt.update_placeholder(name="ç”¨æˆ·")
parallel_prompt = prompt1 | prompt2 | prompt3
```

### 4. Postprocessï¼ˆåå¤„ç†ï¼‰
åå¤„ç†æ¨¡å—æä¾›äº†å¤šç§å“åº”å¤„ç†åŠŸèƒ½ï¼ŒåŒ…æ‹¬ JSON å¤„ç†ã€ç±»å‹è½¬æ¢ã€æ¨¡å¼åŒ¹é…ã€æ–‡æœ¬å¤„ç†å’Œåå¤„ç†å™¨çº§è”ç»„åˆã€‚

```python
# åå¤„ç†ä½¿ç”¨ç¤ºä¾‹
json_pp = JsonKeyExtractorPP(target_key="response")
replace_pp = ReplacePP(replace_map={"æ•æ„Ÿè¯": "***"})
complex_pp = json_pp >> replace_pp
response = await prompt.acall(query=query, postprocessor=complex_pp)
```

### 5. Serverï¼ˆæœåŠ¡å™¨ï¼‰
æœåŠ¡å™¨æ¨¡å—æä¾›äº†å¿«é€Ÿéƒ¨ç½²æ™ºèƒ½ä½“çš„åŠŸèƒ½ï¼Œæ”¯æŒä¸€é”®å‘å¸ƒä¸º RESTful APIã€OpenAI å…¼å®¹æ¥å£ã€æµå¼è¾“å‡ºå’Œè‡ªå®šä¹‰çŠ¶æ€ã€‚

```python
# API éƒ¨ç½²ç¤ºä¾‹
config = APIPublisherConfig(memory_ttl=7200, max_memory_items=2000)
app = publish_agent_api(agent=agent, method="api_logic", config=config)
uvicorn.run(app, host="0.0.0.0", port=8000)
```

## ğŸ¯ ä½¿ç”¨åœºæ™¯

Alphoraæ¡†æ¶é€‚ç”¨äºå¤šç§AIæ™ºèƒ½ä½“åº”ç”¨åœºæ™¯ï¼š

### 1. æ™ºèƒ½å®¢æœç³»ç»Ÿ
- å¤šè½®å¯¹è¯æ”¯æŒ
- ä¸Šä¸‹æ–‡ç†è§£
- ä¸ªæ€§åŒ–å›å¤
- å¿«é€ŸAPIéƒ¨ç½²

### 2. å†…å®¹ç”Ÿæˆä¸ç¿»è¯‘
- å¤šè¯­è¨€åŒæ—¶ç¿»è¯‘
- å†…å®¹æ‰¹é‡ç”Ÿæˆ
- æ ¼å¼ç»Ÿä¸€ç®¡ç†
- å®æ—¶æµå¼è¾“å‡º

### 3. è™šæ‹ŸåŠ©æ‰‹
- å·¥å…·è°ƒç”¨é›†æˆ
- è®°å¿†èƒ½åŠ›
- å¤šä»»åŠ¡å¹¶è¡Œå¤„ç†
- å¯æ‰©å±•çš„åŠŸèƒ½æ¨¡å—

### 4. æ•™è‚²è¾…å¯¼ç³»ç»Ÿ
- ä¸ªæ€§åŒ–æ•™å­¦
- çŸ¥è¯†ç‚¹è®°å¿†ä¸å¤ä¹ 
- å¤šå­¦ç§‘æ”¯æŒ
- äº¤äº’å¼å­¦ä¹ ä½“éªŒ

### 5. ä¼ä¸šå†…éƒ¨å·¥å…·
- çŸ¥è¯†æ£€ç´¢ä¸é—®ç­”
- å·¥ä½œæµç¨‹è‡ªåŠ¨åŒ–
- æ•°æ®å¤„ç†ä¸åˆ†æ
- å›¢é˜Ÿåä½œæ”¯æŒ

## ğŸš€ é«˜çº§åŠŸèƒ½

### 1. å¤šæ¨¡å‹è´Ÿè½½å‡è¡¡

Alphoraæ”¯æŒå°†å¤šä¸ªLLMæ¨¡å‹ç»„åˆä½¿ç”¨ï¼Œå®ç°è´Ÿè½½å‡è¡¡å’Œè‡ªåŠ¨æ•…éšœè½¬ç§»ï¼š

```python
# åˆ›å»ºå¤šä¸ªæ¨¡å‹å®ä¾‹
llm1 = OpenAILike(api_key="key1", base_url="url1", model_name="model1")
llm2 = OpenAILike(api_key="key2", base_url="url2", model_name="model2")

# ç»„åˆæ¨¡å‹å®ç°è´Ÿè½½å‡è¡¡
combined_llm = llm1 + llm2

# ä½¿ç”¨ç»„åˆæ¨¡å‹åˆ›å»ºæ™ºèƒ½ä½“
agent = BaseAgent(llm=combined_llm)
```

### 2. è‡ªå®šä¹‰æµå¼è¾“å‡º

æ”¯æŒè‡ªå®šä¹‰æµå¼è¾“å‡ºå†…å®¹ç±»å‹å’Œæ ¼å¼ï¼š

```python
# è¾“å‡ºçŠ¶æ€ä¿¡æ¯
await agent.stream.astream_message(content="æ­£åœ¨å¤„ç†è¯·æ±‚...", content_type="status")

# è¾“å‡ºå·¥å…·è°ƒç”¨ç»“æœ
await agent.stream.astream_message(content=tool_result, content_type="tool")

# è¾“å‡ºæœ€ç»ˆç»“æœ
await agent.stream.astream_message(content=final_result, content_type="result")

# åœæ­¢æµ
await agent.stream.astop(stop_reason="completed")
```

### 3. é«˜çº§åå¤„ç†ç»„åˆ

æ”¯æŒå¤šä¸ªåå¤„ç†å™¨çº§è”ç»„åˆï¼Œå®ç°å¤æ‚çš„å“åº”å¤„ç†é€»è¾‘ï¼š

```python
# åˆ›å»ºå¤šä¸ªåå¤„ç†å™¨
json_pp = JsonKeyExtractorPP(target_key="data")
filter_pp = FilterPP(pattern=r"\d+")
replace_pp = ReplacePP(replace_map={"old": "new"})

# çº§è”ç»„åˆåå¤„ç†å™¨
complex_pp = json_pp >> filter_pp >> replace_pp

# ä½¿ç”¨ç»„åˆåå¤„ç†å™¨
response = await prompt.acall(query=query, postprocessor=complex_pp)
```

### 4. æ™ºèƒ½ä½“å¹¶è¡Œå·¥ä½œ

æ”¯æŒå¤šä¸ªæ™ºèƒ½ä½“å¹¶è¡Œå·¥ä½œï¼Œæé«˜å¤„ç†æ•ˆç‡ï¼š

```python
# å¹¶è¡Œæç¤ºè¯å¤„ç†
parallel_prompt = prompt1 | prompt2 | prompt3
response = await parallel_prompt.acall(query=query)

# å¤šè¯­è¨€åŒæ—¶ç¿»è¯‘
target_langs = ["en", "jp", "fr", "de"]
await agent.translate(text="ä½ å¥½", target_langs=target_langs)
```

## ğŸ¯ ä½¿ç”¨åœºæ™¯

Alphoraé€‚ç”¨äºå„ç§éœ€è¦AIæ™ºèƒ½ä½“çš„åœºæ™¯ï¼š

- **è™šæ‹ŸåŠ©æ‰‹**ï¼šæ™ºèƒ½å¯¹è¯ã€å¤šè½®äº¤äº’ã€ä¸ªæ€§åŒ–å“åº”
- **æ•™è‚²è¾…å¯¼**ï¼šä¸ªæ€§åŒ–å­¦ä¹ ã€æ™ºèƒ½ç­”ç–‘ã€äº¤äº’å¼ä½“éªŒ
- **ä¼ä¸šå·¥å…·**ï¼šçŸ¥è¯†æ£€ç´¢ã€è‡ªåŠ¨åŒ–æŠ¥å‘Šã€æ™ºèƒ½å®¢æœã€å·¥ä½œæµè‡ªåŠ¨åŒ–
- **å†…å®¹åˆ›ä½œ**ï¼šæ–‡ç« ç”Ÿæˆã€ç¿»è¯‘ã€æ‘˜è¦ã€åˆ›æ„å†™ä½œ
- **æ•°æ®åˆ†æ**ï¼šæ•°æ®è§£è¯»ã€å¯è§†åŒ–å»ºè®®ã€æŠ¥å‘Šç”Ÿæˆ

## ğŸš€ é«˜çº§åŠŸèƒ½

### 1. å¤šæ¨¡å‹è´Ÿè½½å‡è¡¡

æ”¯æŒå¤šæ¨¡å‹è´Ÿè½½å‡è¡¡ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ¨¡å‹ï¼š

```python
# åˆ›å»ºå¤šæ¨¡å‹è´Ÿè½½å‡è¡¡
llms = [OpenAIModel(api_key="key1"), AnthropicModel(api_key="key2")]
load_balanced_llm = load_balancer(llms, strategy="round_robin")
agent = BaseAgent(llm=load_balanced_llm)
```

### 2. è‡ªå®šä¹‰æµå¼è¾“å‡º

æ”¯æŒè‡ªå®šä¹‰æµå¼è¾“å‡ºå¤„ç†ï¼š

```python
async def custom_stream_handler(chunk):
    print(f"[è‡ªå®šä¹‰æµ] {chunk}")

response = await agent.stream_chat("ä½ å¥½", stream_handler=custom_stream_handler)
```

### 3. é«˜çº§åå¤„ç†ç»„åˆ

æ”¯æŒå¤šä¸ªåå¤„ç†å™¨çº§è”ç»„åˆï¼š

```python
# çº§è”åå¤„ç†å™¨
complex_pp = JsonKeyExtractorPP(target_key="sql") >> ReplacePP(replace_map={"æ•æ„Ÿè¯": "***"})
response = await prompt.acall(query=query, postprocessor=complex_pp)
```

### 4. æ™ºèƒ½ä½“å¹¶è¡Œå·¥ä½œ

æ”¯æŒå¤šæ™ºèƒ½ä½“å¹¶è¡Œæ‰§è¡Œï¼š

```python
# å¹¶è¡Œæ‰§è¡Œ
results = await asyncio.gather(
    agent1.chat("ä¸­æ–‡æ€»ç»“ï¼š..."),
    agent2.chat("è‹±æ–‡ç¿»è¯‘ï¼š..."),
    agent3.chat("æå–å…³é”®è¯ï¼š...")
)
```

## â“ å¸¸è§é—®é¢˜

### 1. å¦‚ä½•æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹ï¼Ÿ

å®ç°`BaseLLM`æ¥å£ï¼š

```python
from alphora.models.llms.base import BaseLLM

class MyCustomLLM(BaseLLM):
    async def generate(self, messages, **kwargs):
        # å®ç°è‡ªå®šä¹‰æ¨¡å‹è°ƒç”¨é€»è¾‘
        pass

# ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹
llm = MyCustomLLM(api_key="your-key")
agent = BaseAgent(llm=llm)
```

### 2. å¦‚ä½•è‡ªå®šä¹‰è®°å¿†å­˜å‚¨ï¼Ÿ

å®ç°`BaseMemory`æ¥å£ï¼š

```python
from alphora.memory.base import BaseMemory

class MyCustomMemory(BaseMemory):
    async def add_memory(self, content, **kwargs):
        # å®ç°è‡ªå®šä¹‰è®°å¿†æ·»åŠ é€»è¾‘
        pass

    async def build_history(self, **kwargs):
        # å®ç°è‡ªå®šä¹‰å†å²æ„å»ºé€»è¾‘
        pass

# ä½¿ç”¨è‡ªå®šä¹‰è®°å¿†
agent = BaseAgent(llm=llm, memory=MyCustomMemory())
```

### 3. å¦‚ä½•æ‰©å±•åå¤„ç†å™¨ï¼Ÿ

ç»§æ‰¿`BasePostprocess`ç±»ï¼š

```python
from alphora.postprocess.base_pp import BasePostprocess


class MyCustomPostprocess(BasePostprocess):
  async def process(self, content, **kwargs):
    # å®ç°è‡ªå®šä¹‰åå¤„ç†é€»è¾‘
    return processed_content


# ä½¿ç”¨è‡ªå®šä¹‰åå¤„ç†å™¨
response = await prompt.acall(query=query, postprocessor=MyCustomPostprocess())
```

### 4. å¦‚ä½•ä¼˜åŒ–APIæ€§èƒ½ï¼Ÿ

- ä½¿ç”¨å¤šæ¨¡å‹è´Ÿè½½å‡è¡¡åˆ†æ•£è¯·æ±‚
- åˆç†é…ç½®è®°å¿†æ± å¤§å°å’ŒTTL
- å¯ç”¨æµå¼è¾“å‡ºå‡å°‘ç­‰å¾…æ—¶é—´
- ä½¿ç”¨å¹¶è¡Œå¤„ç†æé«˜å¹¶å‘èƒ½åŠ›
- ä¼˜åŒ–æç¤ºè¯æ¨¡æ¿å‡å°‘æ¨¡å‹è®¡ç®—é‡

## ğŸ“ è¯¦ç»†ç¤ºä¾‹

é¡¹ç›®æä¾›äº†å¤šä¸ªè¯¦ç»†ç¤ºä¾‹ï¼Œå±•ç¤ºäº†æ¡†æ¶çš„å„ç§åŠŸèƒ½ï¼š

### 1. æ™ºèƒ½ä½“åŸºç¡€åŠŸèƒ½ (`examples/1-1-æ™ºèƒ½ä½“åŸºç¡€åŠŸèƒ½.py`)
å±•ç¤ºå¦‚ä½•åˆ›å»ºå’Œä½¿ç”¨ä¸€ä¸ªç®€å•çš„æ™ºèƒ½ä½“ï¼ŒåŒ…æ‹¬åŸºæœ¬çš„å¯¹è¯åŠŸèƒ½ã€‚

```python
from alphora.agent.base_agent import BaseAgent
from alphora.models.llms.openai_like import OpenAILike

# é…ç½®LLM
llm = OpenAILike(api_key="your-api-key", base_url="https://api.example.com/v1", model_name="your-model-name")

# åˆ›å»ºæ™ºèƒ½ä½“
agent = BaseAgent(llm=llm, verbose=True)


# è°ƒç”¨æ™ºèƒ½ä½“
async def main():
  response = await agent.chat(query="ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ")
  print(response)


if __name__ == "__main__":
  import asyncio

  asyncio.run(main())
```

### 2. è®°å¿†ç®¡ç†åŠŸèƒ½ (`examples/1-2-è®°å¿†ç®¡ç†åŠŸèƒ½.py`)
å±•ç¤ºå¦‚ä½•ä½¿ç”¨è®°å¿†æ¨¡å—ä¿å­˜å’Œæ£€ç´¢å¯¹è¯å†å²ï¼Œæ”¯æŒå¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡ã€‚

```python
class MemoryAgent(BaseAgent):
    async def chat_with_memory(self, query: str) -> str:
        # æ„å»ºå†å²å¯¹è¯
        history = self.memory.build_history(memory_id="default", max_round=5)
        
        # åˆ›å»ºåŒ…å«å†å²å¯¹è¯çš„æç¤ºè¯
        prompt = self.create_prompt(
            prompt="æ ¹æ®å†å²å¯¹è¯å’Œå½“å‰é—®é¢˜å›ç­”ï¼š\nå†å²å¯¹è¯ï¼š\n{{history}}\nå½“å‰é—®é¢˜ï¼š{{query}}"
        )
        
        prompt.update_placeholder(history=history)
        response = await prompt.acall(query=query, is_stream=False)
        
        # ä¿å­˜å¯¹è¯åˆ°è®°å¿†ä¸­
        self.memory.add_memory(role="ç”¨æˆ·", content=query)
        self.memory.add_memory(role="åŠ©æ‰‹", content=response)
        
        return response
```

### 3. æç¤ºè¯ç³»ç»ŸåŠŸèƒ½ (`examples/1-3-æç¤ºè¯ç³»ç»ŸåŠŸèƒ½.py`)
å±•ç¤ºå¦‚ä½•ä½¿ç”¨æç¤ºè¯æ¨¡æ¿ç³»ç»Ÿï¼Œæ”¯æŒä»æ–‡ä»¶æˆ–å­—ç¬¦ä¸²åŠ è½½æ¨¡æ¿ã€‚

```python
class PromptAgent(BaseAgent):
    async def chat_with_template(self, query: str, profession: str) -> str:
        # ä»æ–‡ä»¶åŠ è½½æç¤ºè¯æ¨¡æ¿
        prompt = self.create_prompt(
            template_path="prompt_template.tmpl",
            template_desc="é€šç”¨èŒä¸šè§’è‰²å›ç­”æ¨¡æ¿"
        )
        
        # æ›´æ–°æç¤ºè¯å ä½ç¬¦
        prompt.update_placeholder(profession=profession)
        
        # è°ƒç”¨LLMè·å–å›å¤
        response = await prompt.acall(query=query, is_stream=False)
        
        return response
```

### 4. åå¤„ç†åŠŸèƒ½ (`examples/1-4-åå¤„ç†åŠŸèƒ½.py`)
å±•ç¤ºå¦‚ä½•ä½¿ç”¨å„ç§åå¤„ç†å™¨ä»¥åŠå®ƒä»¬çš„ç»„åˆæ¥å¤„ç†æ™ºèƒ½ä½“çš„è¾“å‡ºã€‚

```python
class PostProcessAgent(BaseAgent):
    async def sql_coder(self, query: str, school_name: str):
        prompt = ("è¯·ç¼–å†™SQLè„šæœ¬ï¼Œå…¶ä¸­å­¦æ ¡åç§°ä¸ºPLACEHOLDERï¼Œé—®é¢˜:{{query}}ï¼Œç”¨jsonå†™ï¼ŒåŒ…å«sql, explainä¸¤ä¸ªkey")
        
        # å¤šä¸ªåå¤„ç†å¯è¿›è¡Œçº§è”
        replace_pp = ReplacePP(replace_map={"PLACEHOLDER": school_name})
        json_pp = JsonKeyExtractorPP(target_key="explain")
        complex_pp = json_pp >> replace_pp
        
        prompter = self.create_prompt(prompt=prompt)
        resp = await prompter.acall(query=query, is_stream=True, postprocessor=complex_pp)
        return resp
```

### 5. å¹¶è¡Œæ¨ç† (`examples/1-5-å¹¶è¡Œæ¨ç†.py`)
å±•ç¤ºå¦‚ä½•å¹¶è¡Œä½¿ç”¨å¤šä¸ªæç¤ºè¯è¿›è¡Œæ‰¹é‡å¤„ç†ã€‚

```python
class ParallelAgent(BaseAgent):
    async def translate(self, query: str, target_languages: List[str]):
        prompt = "è¯·å°†{{query}}ç¿»è¯‘ä¸º{{target_language}}"
        
        # åˆ›å»ºå¤šä¸ªå¹¶è¡Œçš„æç¤ºè¯
        prompts = [
            self.create_prompt(prompt=prompt, content_type=lang).
            update_placeholder(target_language=lang)
            for lang in target_languages
        ]
        
        parallel_prompt = ParallelPrompt(prompts=prompts)
        resp = await parallel_prompt.acall(query=query, is_stream=True)
        return resp
```

### 6. å¿«é€ŸAPIéƒ¨ç½²ç¤ºä¾‹ (`examples/1-6-å¿«é€ŸAPIéƒ¨ç½²ç¤ºä¾‹.py`)
å±•ç¤ºå¦‚ä½•ä¸€é”®å°†æ™ºèƒ½ä½“å‘å¸ƒä¸ºRESTful APIï¼Œæ”¯æŒæµå¼è¾“å‡ºå’Œå¤šæ¨¡å‹è´Ÿè½½å‡è¡¡ã€‚

```python
class MyAgent(BaseAgent):
    async def guide(self, query: str, city: str) -> None:
        # æ´¾ç”Ÿæ™ºèƒ½ä½“
        weather_agent = self.derive(WeatherTool)
        
        # æŸ¥è¯¢å¤©æ°”
        weather = await weather_agent.get_weather(city=city)
        
        # åˆ›å»ºæç¤ºè¯
        prompter = self.create_prompt(prompt=PROMPT_GUIDE)
        prompter.update_placeholder(city=city, weather=weather)
        
        # è°ƒç”¨LLM
        await prompter.acall(query=query, is_stream=True, force_json=True)
        
    async def api_logic(self, request: OpenAIRequest):
        query = request.get_user_query()
        await self.guide(query=query, city='åŒ—äº¬')

# éƒ¨ç½²API
if __name__ == '__main__':
    import uvicorn
    from alphora.server.quick_api import publish_agent_api, APIPublisherConfig
    
    agent = MyAgent(llm=llm)
    config = APIPublisherConfig(memory_ttl=7200, max_memory_items=2000)
    app = publish_agent_api(agent=agent, method="api_logic", config=config)
    uvicorn.run(app, host="0.0.0.0", port=8002)
```

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ä»£ç ã€æŠ¥å‘Šé—®é¢˜æˆ–æå‡ºå»ºè®®ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Fork ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. æ‰“å¼€ Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ“§ è”ç³»æ–¹å¼

- ä½œè€…ï¼šTian tian
- é‚®ç®±ï¼štiantianit@chinamobile.com



