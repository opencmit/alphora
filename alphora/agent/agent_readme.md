# Alphora Agent

**æ™ºèƒ½ä½“æ ¸å¿ƒæ¡†æ¶ç»„ä»¶**

Agent æ˜¯ Alphora æ¡†æ¶ä¸­çš„æ™ºèƒ½ä½“æ ¸å¿ƒç»„ä»¶ï¼Œæä¾›å¯ç»„åˆã€å¯æ´¾ç”Ÿçš„æ™ºèƒ½ä½“æ¶æ„ã€‚å®ƒæ”¯æŒå¤šç§æ™ºèƒ½ä½“æ¨¡å¼ï¼ˆå¦‚ ReActï¼‰ã€æµå¼è¾“å‡ºã€è°ƒè¯•è¿½è¸ªï¼Œå¹¶èƒ½ä¸ Memoryã€Prompter ç­‰ç»„ä»¶æ— ç¼é›†æˆï¼Œæ„å»ºå¤æ‚çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€‚

## ç‰¹æ€§

- ğŸ§¬ **æ´¾ç”Ÿæœºåˆ¶** - æ”¯æŒä»çˆ¶æ™ºèƒ½ä½“æ´¾ç”Ÿå­æ™ºèƒ½ä½“ï¼Œå…±äº«é…ç½®ä¸è®°å¿†
- ğŸ”„ **ReAct æ¨¡å¼** - å†…ç½®æ¨ç†-è¡ŒåŠ¨å¾ªç¯ï¼Œè‡ªåŠ¨å¤„ç†å·¥å…·è°ƒç”¨
- ğŸ“¡ **æµå¼è¾“å‡º** - å®Œæ•´çš„å¼‚æ­¥æµå¼å“åº”æ”¯æŒï¼Œå…¼å®¹ OpenAI SSE
- ğŸ›  **å·¥å…·é›†æˆ** - ä¸ ToolRegistry æ·±åº¦é›†æˆï¼Œæ”¯æŒ Function Calling
- ğŸ› **è°ƒè¯•è¿½è¸ª** - å†…ç½® Debugger æ”¯æŒï¼Œå¯è§†åŒ–æ™ºèƒ½ä½“æ‰§è¡Œæµç¨‹
- ğŸ”— **ç»„åˆèƒ½åŠ›** - æ”¯æŒæ™ºèƒ½ä½“é“¾å¼ç»„åˆä¸å¹¶è¡Œæ‰§è¡Œ
- ğŸ’¾ **çŠ¶æ€å…±äº«** - é€šè¿‡ MemoryManager å®ç°è·¨æ™ºèƒ½ä½“çŠ¶æ€å…±äº«
- âš™ï¸ **é…ç½®ç»§æ‰¿** - é…ç½®å­—å…¸è‡ªåŠ¨ä¼ é€’ç»™æ´¾ç”Ÿæ™ºèƒ½ä½“

## å®‰è£…

```bash
pip install alphora
```

## å¿«é€Ÿå¼€å§‹

```python
from alphora.agent import BaseAgent, ReActAgent
from alphora.models import OpenAILike

# åˆ›å»ºåŸºç¡€æ™ºèƒ½ä½“
llm = OpenAILike(model_name="gpt-4")
agent = BaseAgent(llm=llm, verbose=True)

# åˆ›å»ºæç¤ºè¯å¹¶è°ƒç”¨
prompt = agent.create_prompt(
    system_prompt="ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹",
    user_prompt="{{query}}"
)
response = await prompt.acall(query="ä½ å¥½ï¼")
```

## ç›®å½•

- [åŸºç¡€ç”¨æ³•](#åŸºç¡€ç”¨æ³•)
- [æ´¾ç”Ÿæœºåˆ¶](#æ´¾ç”Ÿæœºåˆ¶)
- [ReAct æ™ºèƒ½ä½“](#react-æ™ºèƒ½ä½“)
- [æµå¼è¾“å‡º](#æµå¼è¾“å‡º)
- [é…ç½®ç®¡ç†](#é…ç½®ç®¡ç†)
- [è°ƒè¯•è¿½è¸ª](#è°ƒè¯•è¿½è¸ª)
- [ç¬¬ä¸‰æ–¹ API è°ƒç”¨](#ç¬¬ä¸‰æ–¹-api-è°ƒç”¨)
- [API å‚è€ƒ](#api-å‚è€ƒ)

---

## åŸºç¡€ç”¨æ³•

### åˆ›å»ºæ™ºèƒ½ä½“

```python
from alphora.agent import BaseAgent
from alphora.models import OpenAILike
from alphora.memory import MemoryManager

# åŸºç¡€åˆ›å»º
agent = BaseAgent(llm=OpenAILike())

# å¸¦å®Œæ•´é…ç½®
agent = BaseAgent(
    llm=OpenAILike(model_name="gpt-4"),
    memory=MemoryManager(),
    verbose=True,
    agent_id="my_agent",
    config={"max_retries": 3}
)
```

### åˆ›å»ºæç¤ºè¯

```python
# ç®€å•æ¨¡å¼
prompt = agent.create_prompt(
    user_prompt="è¯·å›ç­”ï¼š{{query}}"
)
response = await prompt.acall(query="ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ")

# å¸¦ç³»ç»Ÿæç¤º
prompt = agent.create_prompt(
    system_prompt="ä½ æ˜¯ä¸€ä¸ª{{role}}ä¸“å®¶",
    user_prompt="{{query}}"
)
prompt.update_placeholder(role="Python")
response = await prompt.acall(query="å¦‚ä½•ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼ï¼Ÿ")

# ä»æ¨¡æ¿æ–‡ä»¶åŠ è½½
prompt = agent.create_prompt(
    template_path="prompts/qa_template.txt",
    content_type="char"
)
```

### æµå¼è°ƒç”¨

```python
# å¼‚æ­¥æµå¼ï¼ˆæ¨èï¼‰
response = await prompt.acall(
    query="å†™ä¸€é¦–è¯—",
    is_stream=True
)

# å¸¦å›è°ƒçš„æµå¼
from alphora.server.stream_responser import DataStreamer

agent = BaseAgent(
    llm=llm,
    callback=DataStreamer(websocket)  # è‡ªåŠ¨æ¨é€åˆ°å®¢æˆ·ç«¯
)
```

---

## æ´¾ç”Ÿæœºåˆ¶

æ´¾ç”Ÿæœºåˆ¶å…è®¸ä»çˆ¶æ™ºèƒ½ä½“åˆ›å»ºå­æ™ºèƒ½ä½“ï¼Œå…±äº« LLMã€Memoryã€Config ç­‰èµ„æºã€‚

### ä»ç±»æ´¾ç”Ÿ

```python
from alphora.agent import BaseAgent

class AnalysisAgent(BaseAgent):
    agent_type = "AnalysisAgent"
    
    def __init__(self, domain: str = "general", **kwargs):
        super().__init__(**kwargs)
        self.domain = domain

# ä¸»æ™ºèƒ½ä½“æ´¾ç”Ÿå­æ™ºèƒ½ä½“
main_agent = BaseAgent(llm=llm, config={"debug": True})
analysis_agent = main_agent.derive(AnalysisAgent)

# å­æ™ºèƒ½ä½“è‡ªåŠ¨ç»§æ‰¿ï¼š
# - llm
# - memory
# - config
# - callback
# - verbose
```

### ä»å®ä¾‹æ´¾ç”Ÿ

```python
# é¢„é…ç½®çš„å®ä¾‹
file_agent = FileViewerAgent(base_dir="/data/files")

# æ´¾ç”Ÿæ—¶ä¿ç•™å®ä¾‹ç‰¹æœ‰å±æ€§
file_agent = main_agent.derive(file_agent)
# file_agent.base_dir ä»ç„¶æ˜¯ "/data/files"
# ä½† llm, memory, config å·²ä» main_agent ç»§æ‰¿
```

### æ´¾ç”Ÿé“¾

```python
# å¤šå±‚æ´¾ç”Ÿ
root_agent = BaseAgent(llm=llm, config={"project": "demo"})
task_agent = root_agent.derive(TaskAgent)
sub_task_agent = task_agent.derive(SubTaskAgent)

# æ‰€æœ‰æ™ºèƒ½ä½“å…±äº«åŒä¸€ä¸ª memory å®ä¾‹
root_agent.memory.add_user("ä½ å¥½")
# task_agent å’Œ sub_task_agent éƒ½èƒ½çœ‹åˆ°è¿™æ¡æ¶ˆæ¯
```

---

## ReAct æ™ºèƒ½ä½“

ReAct (Reasoning + Acting) æ™ºèƒ½ä½“è‡ªåŠ¨å¤„ç†å·¥å…·è°ƒç”¨å¾ªç¯ã€‚

### åŸºç¡€ä½¿ç”¨

```python
from alphora.agent import ReActAgent
from alphora.tools.decorators import tool

# å®šä¹‰å·¥å…·
@tool
def get_weather(city: str) -> str:
    """è·å–åŸå¸‚å¤©æ°”"""
    return f"{city}ä»Šå¤©æ™´ï¼Œ25Â°C"

@tool  
def search(query: str) -> str:
    """æœç´¢ä¿¡æ¯"""
    return f"å…³äº{query}çš„æœç´¢ç»“æœ..."

# åˆ›å»º ReAct æ™ºèƒ½ä½“
agent = ReActAgent(
    llm=OpenAILike(model_name="gpt-4"),
    tools=[get_weather, search],
    system_prompt="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥æŸ¥è¯¢å¤©æ°”å’Œæœç´¢ä¿¡æ¯",
    max_iterations=10
)

# æ‰§è¡Œ
response = await agent.run("åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")
```

### è‡ªå®šä¹‰ç³»ç»Ÿæç¤º

```python
agent = ReActAgent(
    llm=llm,
    tools=[get_weather, search, calculate],
    system_prompt="""ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æåŠ©æ‰‹ã€‚
    
    å·¥ä½œæµç¨‹ï¼š
    1. ç†è§£ç”¨æˆ·éœ€æ±‚
    2. é€‰æ‹©åˆé€‚çš„å·¥å…·
    3. åˆ†æç»“æœ
    4. ç»™å‡ºç»“è®º
    
    è¯·å§‹ç»ˆè§£é‡Šä½ çš„æ¨ç†è¿‡ç¨‹ã€‚"""
)
```

---

## æµå¼è¾“å‡º

### Stream ç±»

```python
from alphora.agent.stream import Stream

stream = Stream(callback=data_streamer)

# å‘é€æµå¼æ¶ˆæ¯
await stream.astream_message(
    content="è¿™æ˜¯ä¸€æ®µæ–‡å­—",
    content_type="char",
    interval=0.05  # æ¨¡æ‹Ÿæ‰“å­—æ•ˆæœ
)

# ç»ˆæ­¢æµ
await stream.astop(stop_reason="complete")
```

### æµå¼ç”Ÿæˆå™¨å¤„ç†

```python
from alphora.models.llms.stream_helper import BaseGenerator, GeneratorOutput

# å°†ç”Ÿæˆå™¨è½¬ä¸ºå“åº”
generator = await llm.aget_streaming_response(message="ä½ å¥½")
response = await stream.astream_to_response(
    generator,
    post_processors=[my_processor]  # å¯é€‰çš„åå¤„ç†å™¨
)
```

### å†…å®¹ç±»å‹

| content_type | è¯´æ˜ |
|--------------|------|
| `char` | æ™®é€šæ–‡æœ¬å­—ç¬¦ |
| `think` | æ¨ç†/æ€è€ƒå†…å®¹ |
| `result` | æœ€ç»ˆç»“æœ |
| `sql` | SQL æŸ¥è¯¢ |
| `chart` | å›¾è¡¨æ•°æ® |
| `[STREAM_IGNORE]` | ä¸å‘é€åˆ°æµï¼Œä½†è®¡å…¥å“åº” |
| `[RESPONSE_IGNORE]` | å‘é€åˆ°æµï¼Œä½†ä¸è®¡å…¥å“åº” |
| `[BOTH_IGNORE]` | æ—¢ä¸å‘é€ä¹Ÿä¸è®¡å…¥ |

---

## é…ç½®ç®¡ç†

### æ›´æ–°é…ç½®

```python
agent = BaseAgent(llm=llm)

# è®¾ç½®é…ç½®é¡¹
agent.update_config("max_retries", 3)
agent.update_config("timeout", 30)

# æ‰¹é‡è®¾ç½®ï¼ˆé€šè¿‡åˆå§‹åŒ–ï¼‰
agent = BaseAgent(
    llm=llm,
    config={
        "max_retries": 3,
        "timeout": 30,
        "debug": True
    }
)
```

### è·å–é…ç½®

```python
# è·å–é…ç½®å€¼
retries = agent.get_config("max_retries")

# é…ç½®ä¸å­˜åœ¨æ—¶ä¼šæä¾›å»ºè®®
try:
    agent.get_config("max_retry")  # æ‹¼å†™é”™è¯¯
except KeyError as e:
    print(e)  # "Config 'max_retry' not found. Did you mean 'max_retries'?"
```

### é…ç½®ç»§æ‰¿

```python
parent = BaseAgent(llm=llm, config={"project": "demo", "version": "1.0"})
child = parent.derive(ChildAgent)

# å­æ™ºèƒ½ä½“è‡ªåŠ¨ç»§æ‰¿é…ç½®
print(child.get_config("project"))  # "demo"

# å­æ™ºèƒ½ä½“å¯ä»¥è¦†ç›–
child.update_config("version", "2.0")
```

---

## è°ƒè¯•è¿½è¸ª

### å¯ç”¨è°ƒè¯•å™¨

```python
agent = BaseAgent(
    llm=llm,
    debugger=True,
    debugger_port=9527
)

# è®¿é—® http://localhost:9527 æŸ¥çœ‹è°ƒè¯•ç•Œé¢
```

### è¿½è¸ªå†…å®¹

- æ™ºèƒ½ä½“åˆ›å»ºä¸æ´¾ç”Ÿå…³ç³»
- Prompt åˆ›å»ºä¸æ¸²æŸ“
- LLM è°ƒç”¨ï¼ˆè¯·æ±‚/å“åº”/Token ç»Ÿè®¡ï¼‰
- å·¥å…·æ‰§è¡Œ
- æµå¼è¾“å‡º

---

## ç¬¬ä¸‰æ–¹ API è°ƒç”¨

`afetch_stream` æ–¹æ³•æ”¯æŒè°ƒç”¨ç¬¬ä¸‰æ–¹æµå¼ API å¹¶é€ä¼ è¾“å‡ºã€‚

### æ ‡å‡† OpenAI æ ¼å¼

```python
# è‡ªåŠ¨è§£æ OpenAI SSE æ ¼å¼
response = await agent.afetch_stream(
    url="https://api.example.com/v1/chat/completions",
    payload={
        "model": "gpt-4",
        "messages": [{"role": "user", "content": "ä½ å¥½"}],
        "stream": True
    },
    content_type="char"
)
```

### è‡ªå®šä¹‰è§£æå™¨

```python
# è‡ªå®šä¹‰è§£æé€»è¾‘
def my_parser(chunk: bytes) -> str:
    data = json.loads(chunk)
    return data.get("text", "")

response = await agent.afetch_stream(
    url="https://custom-api.com/generate",
    payload={"prompt": "ä½ å¥½"},
    parser_func=my_parser,
    headers={"Authorization": "Bearer xxx"}
)
```

---

## API å‚è€ƒ

### BaseAgent

#### æ„é€ å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `llm` | `OpenAILike` | `None` | LLM å®ä¾‹ |
| `verbose` | `bool` | `False` | è¯¦ç»†æ—¥å¿— |
| `agent_id` | `str` | `uuid` | æ™ºèƒ½ä½“ ID |
| `callback` | `DataStreamer` | `None` | æµå¼å›è°ƒ |
| `debugger` | `bool` | `False` | å¯ç”¨è°ƒè¯•å™¨ |
| `debugger_port` | `int` | `9527` | è°ƒè¯•å™¨ç«¯å£ |
| `config` | `Dict` | `{}` | é…ç½®å­—å…¸ |
| `memory` | `MemoryManager` | `None` | è®°å¿†ç®¡ç†å™¨ |

#### æ–¹æ³•

| æ–¹æ³• | è¯´æ˜ |
|------|------|
| `create_prompt(user_prompt, system_prompt, template_path, ...)` | åˆ›å»ºæç¤ºè¯å®ä¾‹ |
| `derive(agent_cls_or_instance, **kwargs)` | æ´¾ç”Ÿå­æ™ºèƒ½ä½“ |
| `update_config(key, value)` | æ›´æ–°é…ç½®é¡¹ |
| `get_config(key)` | è·å–é…ç½®é¡¹ |
| `afetch_stream(url, payload, parser_func, ...)` | è°ƒç”¨ç¬¬ä¸‰æ–¹æµå¼ API |

### ReActAgent

#### æ„é€ å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `llm` | `OpenAILike` | å¿…å¡« | LLM å®ä¾‹ |
| `tools` | `List[Tool\|Callable]` | å¿…å¡« | å·¥å…·åˆ—è¡¨ |
| `system_prompt` | `str` | `""` | ç³»ç»Ÿæç¤ºè¯ |
| `max_iterations` | `int` | `10` | æœ€å¤§è¿­ä»£æ¬¡æ•° |

#### æ–¹æ³•

| æ–¹æ³• | è¯´æ˜ |
|------|------|
| `run(query)` | æ‰§è¡Œå®Œæ•´çš„å·¥å…·è°ƒç”¨å¾ªç¯ |

### Stream

#### æ–¹æ³•

| æ–¹æ³• | è¯´æ˜ |
|------|------|
| `astream_message(content, content_type, interval)` | å¼‚æ­¥å‘é€æµå¼æ¶ˆæ¯ |
| `stream_message(content, content_type, interval)` | åŒæ­¥å‘é€æµå¼æ¶ˆæ¯ï¼ˆä¸æ¨èï¼‰ |
| `astop(stop_reason)` | å¼‚æ­¥ç»ˆæ­¢æµ |
| `stop(stop_reason)` | åŒæ­¥ç»ˆæ­¢æµï¼ˆä¸æ¨èï¼‰ |
| `astream_to_response(generator, post_processors)` | å°†ç”Ÿæˆå™¨è½¬ä¸ºå“åº”å­—ç¬¦ä¸² |
| `stream_to_response(generator, post_processors)` | åŒæ­¥ç‰ˆæœ¬ï¼ˆä¸æ¨èï¼‰ |