# Alphora Server

**å¿«é€Ÿ API å‘å¸ƒç»„ä»¶**

Server æ˜¯ Alphora æ¡†æ¶çš„ API å‘å¸ƒæ¨¡å—ï¼Œæä¾›ä¸€é”®å°† Agent å‘å¸ƒä¸º OpenAI å…¼å®¹ API çš„èƒ½åŠ›ã€‚å®ƒæ”¯æŒæµå¼/éæµå¼å“åº”ã€ä¼šè¯è®°å¿†ç®¡ç†ã€è‡ªåŠ¨è¿‡æœŸæ¸…ç†ç­‰ç‰¹æ€§ï¼Œè®©ä½ åªéœ€å‡ è¡Œä»£ç å°±èƒ½å°†æ™ºèƒ½ä½“åº”ç”¨å¯¹å¤–æä¾›æœåŠ¡ã€‚

## ç‰¹æ€§

- ğŸš€ **ä¸€é”®å‘å¸ƒ** - ä¸€è¡Œä»£ç å°† Agent å‘å¸ƒä¸º RESTful API
- ğŸ”„ **OpenAI å…¼å®¹** - å®Œå…¨å…¼å®¹ OpenAI chat/completions æ¥å£æ ¼å¼
- ğŸŒŠ **æµå¼å“åº”** - æ”¯æŒ SSE æµå¼è¾“å‡ºï¼Œå®æ—¶è¿”å›ç”Ÿæˆå†…å®¹
- ğŸ’¾ **ä¼šè¯ç®¡ç†** - å†…ç½®ä¼šè¯è®°å¿†æ± ï¼Œæ”¯æŒå¤šè½®å¯¹è¯
- â° **è‡ªåŠ¨æ¸…ç†** - TTL è¿‡æœŸ + LRU å®¹é‡æ§åˆ¶ï¼Œè‡ªåŠ¨æ¸…ç†è¿‡æœŸä¼šè¯
- ğŸ”’ **å®ä¾‹éš”ç¦»** - æ¯ä¸ªè¯·æ±‚åˆ›å»ºç‹¬ç«‹ Agent å®ä¾‹ï¼Œé¿å…çŠ¶æ€æ±¡æŸ“

## å®‰è£…

```bash
pip install alphora
pip install fastapi uvicorn  # ä¾èµ–
```

## å¿«é€Ÿå¼€å§‹

```python
import uvicorn
from alphora.server.quick_api import publish_agent_api, APIPublisherConfig
from alphora.agent import BaseAgent
from alphora.models.llms import OpenAILike

# 1. åˆ›å»º LLM
llm = OpenAILike(
    base_url="https://api.openai.com/v1",
    model_name="gpt-4",
    api_key="your-api-key"
)

# 2. åˆ›å»º Agent
agent = MyAgent(llm=llm)

# 3. å‘å¸ƒ API
app = publish_agent_api(
    agent=agent,
    method="run",  # Agent çš„å¼‚æ­¥æ–¹æ³•å
)

# 4. å¯åŠ¨æœåŠ¡
if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

å¯åŠ¨åè®¿é—®ï¼š`POST http://localhost:8000/alphadata/chat/completions`

## ç›®å½•

- [API å‘å¸ƒ](#api-å‘å¸ƒ)
- [é…ç½®é€‰é¡¹](#é…ç½®é€‰é¡¹)
- [è¯·æ±‚æ ¼å¼](#è¯·æ±‚æ ¼å¼)
- [å“åº”æ ¼å¼](#å“åº”æ ¼å¼)
- [ä¼šè¯ç®¡ç†](#ä¼šè¯ç®¡ç†)
- [Agent æ–¹æ³•è§„èŒƒ](#agent-æ–¹æ³•è§„èŒƒ)
- [æµå¼å“åº”](#æµå¼å“åº”)
- [å®Œæ•´ç¤ºä¾‹](#å®Œæ•´ç¤ºä¾‹)
- [API å‚è€ƒ](#api-å‚è€ƒ)

---

## API å‘å¸ƒ

### publish_agent_api

æ ¸å¿ƒå‡½æ•°ï¼Œå°† Agent å‘å¸ƒä¸º FastAPI åº”ç”¨ã€‚

```python
from alphora.server.quick_api import publish_agent_api

app = publish_agent_api(
    agent=agent,          # Agent å®ä¾‹
    method="run",         # è¦æš´éœ²çš„å¼‚æ­¥æ–¹æ³•å
    config=config         # å¯é€‰é…ç½®
)
```

**å‚æ•°è¯´æ˜**ï¼š

| å‚æ•° | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `agent` | `BaseAgent` | Agent å®ä¾‹ |
| `method` | `str` | è¦æš´éœ²çš„å¼‚æ­¥æ–¹æ³•å |
| `config` | `APIPublisherConfig` | API é…ç½®ï¼ˆå¯é€‰ï¼‰ |

**è¿”å›å€¼**ï¼šFastAPI åº”ç”¨å®ä¾‹ï¼Œå¯ç›´æ¥ç”¨ uvicorn è¿è¡Œã€‚

### å¯åŠ¨æœåŠ¡

```python
import uvicorn

# æ–¹å¼ 1ï¼šç›´æ¥è¿è¡Œ
uvicorn.run(app, host="0.0.0.0", port=8000)

# æ–¹å¼ 2ï¼šå‘½ä»¤è¡Œè¿è¡Œ
# uvicorn api_server:app --host 0.0.0.0 --port 8000 --reload
```

---

## é…ç½®é€‰é¡¹

### APIPublisherConfig

```python
from alphora.server.quick_api import APIPublisherConfig

config = APIPublisherConfig(
    path="/alphadata",           # API åŸºç¡€è·¯å¾„
    memory_ttl=3600,             # ä¼šè¯è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
    max_memory_items=1000,       # æœ€å¤§ä¼šè¯æ•°
    auto_clean_interval=600,     # è‡ªåŠ¨æ¸…ç†é—´éš”ï¼ˆç§’ï¼‰
    api_title="My Agent API",    # API æ–‡æ¡£æ ‡é¢˜
    api_description="Agent API"  # API æ–‡æ¡£æè¿°
)

app = publish_agent_api(agent, "run", config=config)
```

**é…ç½®é¡¹è¯´æ˜**ï¼š

| é…ç½®é¡¹ | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|------|--------|------|
| `path` | `str` | `"/alphadata"` | API åŸºç¡€è·¯å¾„ï¼Œå®Œæ•´è·¯å¾„ä¸º `{path}/chat/completions` |
| `memory_ttl` | `int` | `3600` | ä¼šè¯è®°å¿†è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ |
| `max_memory_items` | `int` | `1000` | è®°å¿†æ± æœ€å¤§ä¼šè¯æ•° |
| `auto_clean_interval` | `int` | `600` | è‡ªåŠ¨æ¸…ç†é—´éš”ï¼ˆç§’ï¼‰ |
| `api_title` | `str` | `"Alphora Agent API Service"` | API æ–‡æ¡£æ ‡é¢˜ |
| `api_description` | `str` | `"Auto-generated API..."` | API æ–‡æ¡£æè¿° |

### åŠ¨æ€æ ‡é¢˜

æ”¯æŒåœ¨æ ‡é¢˜å’Œæè¿°ä¸­ä½¿ç”¨å ä½ç¬¦ï¼š

```python
config = APIPublisherConfig(
    api_title="{agent_name} API Service",      # ä¼šæ›¿æ¢ä¸º Agent ç±»å
    api_description="{agent_name}.{method_name} API"  # ä¼šæ›¿æ¢ä¸ºæ–¹æ³•å
)
```

---

## è¯·æ±‚æ ¼å¼

### OpenAIRequest

API æ¥æ”¶ OpenAI å…¼å®¹æ ¼å¼çš„è¯·æ±‚ï¼š

```json
{
    "model": "gpt-4",
    "messages": [
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "ä½ å¥½"}
    ],
    "stream": true,
    "session_id": "user-session-001",
    "user": "user-123"
}
```

**å­—æ®µè¯´æ˜**ï¼š

| å­—æ®µ | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|------|------|------|------|
| `model` | `str` | å¦ | æ¨¡å‹åç§°ï¼ˆå¯å¿½ç•¥ï¼Œç”± Agent å†³å®šï¼‰ |
| `messages` | `List[Message]` | å¦ | æ¶ˆæ¯åˆ—è¡¨ |
| `stream` | `bool` | å¦ | æ˜¯å¦æµå¼å“åº”ï¼Œé»˜è®¤ `true` |
| `session_id` | `str` | å¦ | ä¼šè¯ IDï¼Œç”¨äºå¤šè½®å¯¹è¯ |
| `user` | `str` | å¦ | ç”¨æˆ·æ ‡è¯† |

### Message æ ¼å¼

```python
{
    "role": "user",      # system / user / assistant
    "content": "ä½ å¥½"    # å­—ç¬¦ä¸²æˆ–å¤æ‚å¯¹è±¡
}
```

### ä½¿ç”¨ curl è°ƒç”¨

```bash
# æµå¼è¯·æ±‚
curl -X POST http://localhost:8000/alphadata/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [{"role": "user", "content": "ä½ å¥½"}],
    "stream": true,
    "session_id": "test-session"
  }'

# éæµå¼è¯·æ±‚
curl -X POST http://localhost:8000/alphadata/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [{"role": "user", "content": "ä½ å¥½"}],
    "stream": false
  }'
```

### ä½¿ç”¨ Python è°ƒç”¨

```python
import requests

# éæµå¼
response = requests.post(
    "http://localhost:8000/alphadata/chat/completions",
    json={
        "messages": [{"role": "user", "content": "ä½ å¥½"}],
        "stream": False,
        "session_id": "my-session"
    }
)
print(response.json())

# æµå¼
response = requests.post(
    "http://localhost:8000/alphadata/chat/completions",
    json={
        "messages": [{"role": "user", "content": "ä½ å¥½"}],
        "stream": True
    },
    stream=True
)
for line in response.iter_lines():
    if line:
        print(line.decode())
```

### ä½¿ç”¨ OpenAI SDK è°ƒç”¨

```python
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:8000/alphadata",
    api_key="not-needed"  # å¦‚æœä¸éœ€è¦è®¤è¯
)

# æµå¼
stream = client.chat.completions.create(
    model="agent",
    messages=[{"role": "user", "content": "ä½ å¥½"}],
    stream=True,
    extra_body={"session_id": "my-session"}
)

for chunk in stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="")
```

---

## å“åº”æ ¼å¼

### æµå¼å“åº”ï¼ˆSSEï¼‰

æµå¼å“åº”ä½¿ç”¨ Server-Sent Events (SSE) æ ¼å¼ï¼š

```
data: {"id":"cmpl-xxx","object":"chat.completion.chunk","created":1234567890,"model":"AlphaData","choices":[{"index":0,"delta":{"content":"ä½ ","content_type":"text"},"finish_reason":null}]}

data: {"id":"cmpl-xxx","object":"chat.completion.chunk","created":1234567890,"model":"AlphaData","choices":[{"index":0,"delta":{"content":"å¥½","content_type":"text"},"finish_reason":null}]}

data: {"id":"cmpl-xxx","object":"chat.completion.chunk","created":1234567890,"model":"AlphaData","choices":[{"index":0,"delta":{"content":"","content_type":"stop"},"finish_reason":"stop"}]}
```

**å­—æ®µè¯´æ˜**ï¼š

| å­—æ®µ | è¯´æ˜ |
|------|------|
| `id` | å“åº”å”¯ä¸€æ ‡è¯† |
| `object` | å›ºå®šä¸º `chat.completion.chunk` |
| `created` | åˆ›å»ºæ—¶é—´æˆ³ |
| `model` | æ¨¡å‹åç§° |
| `choices[0].delta.content` | å†…å®¹ç‰‡æ®µ |
| `choices[0].delta.content_type` | å†…å®¹ç±»å‹ |
| `choices[0].finish_reason` | ç»“æŸåŸå› ï¼š`stop` / `timeout` |

### éæµå¼å“åº”

éæµå¼å“åº”è¿”å›å®Œæ•´ JSONï¼Œå†…å®¹æŒ‰ç±»å‹èšåˆä¸º XML æ ¼å¼ï¼š

```json
{
    "id": "cmpl-xxx",
    "object": "chat.completion",
    "created": 1234567890,
    "model": "AlphaData",
    "choices": [{
        "index": 0,
        "delta": {
            "content": "<content type=\"text\">ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„ï¼Ÿ</content><content type=\"thinking\">ç”¨æˆ·åœ¨æ‰“æ‹›å‘¼</content>",
            "content_type": "mixed-xml"
        },
        "finish_reason": "stop"
    }]
}
```

### å†…å®¹ç±»å‹

Agent å¯ä»¥è¾“å‡ºä¸åŒç±»å‹çš„å†…å®¹ï¼š

| content_type | è¯´æ˜ |
|--------------|------|
| `text` | æ™®é€šæ–‡æœ¬ |
| `thinking` | æ€è€ƒè¿‡ç¨‹ |
| `code` | ä»£ç å— |
| `tool_call` | å·¥å…·è°ƒç”¨ |
| `stop` | ç»“æŸæ ‡è®° |
| `mixed-xml` | éæµå¼å“åº”çš„èšåˆæ ¼å¼ |

---

## ä¼šè¯ç®¡ç†

### ä¼šè¯è®°å¿†æ± 

Server å†…ç½®ä¼šè¯è®°å¿†æ± ï¼Œè‡ªåŠ¨ç®¡ç†å¤šè½®å¯¹è¯çš„ä¸Šä¸‹æ–‡ï¼š

```python
config = APIPublisherConfig(
    memory_ttl=3600,         # ä¼šè¯ 1 å°æ—¶åè¿‡æœŸ
    max_memory_items=1000,   # æœ€å¤šä¿å­˜ 1000 ä¸ªä¼šè¯
    auto_clean_interval=600  # æ¯ 10 åˆ†é’Ÿæ¸…ç†ä¸€æ¬¡
)
```

### ä¼šè¯ ID

é€šè¿‡ `session_id` å­—æ®µå®ç°å¤šè½®å¯¹è¯ï¼š

```python
# ç¬¬ä¸€è½®å¯¹è¯
requests.post(url, json={
    "messages": [{"role": "user", "content": "æˆ‘å«å¼ ä¸‰"}],
    "session_id": "user-001"
})

# ç¬¬äºŒè½®å¯¹è¯ï¼ˆåŒä¸€ä¼šè¯ï¼‰
requests.post(url, json={
    "messages": [{"role": "user", "content": "æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ"}],
    "session_id": "user-001"  # ç›¸åŒçš„ session_id
})
# Agent ä¼šè®°ä½ä¸Šæ–‡ï¼Œå›ç­”"å¼ ä¸‰"
```

### æ¸…ç†ç­–ç•¥

è®°å¿†æ± é‡‡ç”¨åŒé‡æ¸…ç†ç­–ç•¥ï¼š

1. **TTL è¿‡æœŸæ¸…ç†**ï¼šè¶…è¿‡ `memory_ttl` æœªè®¿é—®çš„ä¼šè¯è‡ªåŠ¨æ¸…ç†
2. **LRU å®¹é‡æ§åˆ¶**ï¼šè¶…è¿‡ `max_memory_items` æ—¶ï¼Œæ¸…ç†æœ€ä¹…æœªè®¿é—®çš„ä¼šè¯

### è‡ªå®šä¹‰ Memory ç±»

Agent å¯ä»¥æŒ‡å®šé»˜è®¤çš„ Memory ç±»ï¼š

```python
from alphora.agent import BaseAgent
from alphora.memory import MemoryManager

class MyAgent(BaseAgent):
    default_memory_cls = MemoryManager  # è‡ªå®šä¹‰ Memory ç±»
    
    async def run(self, request: OpenAIRequest):
        # self.memory ä¼šè‡ªåŠ¨ä½¿ç”¨ default_memory_cls åˆ›å»º
        pass
```

---

## Agent æ–¹æ³•è§„èŒƒ

### æ–¹æ³•ç­¾å

æš´éœ²çš„ Agent æ–¹æ³•å¿…é¡»æ»¡è¶³ä»¥ä¸‹è¦æ±‚ï¼š

```python
from alphora.server.openai_request_body import OpenAIRequest

class MyAgent(BaseAgent):
    async def run(self, request: OpenAIRequest):
        """
        å¿…é¡»æ˜¯ï¼š
        1. async def å®šä¹‰çš„å¼‚æ­¥æ–¹æ³•
        2. åªæœ‰ä¸€ä¸ªå‚æ•°
        3. å‚æ•°ç±»å‹æ³¨è§£ä¸º OpenAIRequest
        """
        pass
```

### ä½¿ç”¨ OpenAIRequest

```python
async def run(self, request: OpenAIRequest):
    # è·å–ç”¨æˆ·è¾“å…¥
    user_query = request.get_user_query()
    
    # è·å–æ‰€æœ‰æ¶ˆæ¯
    messages = request.messages
    
    # è·å–ä¼šè¯ ID
    session_id = request.session_id
    
    # è·å–è¯·æ±‚å¤´
    auth_header = request.get_header("Authorization")
    all_headers = request.get_header()  # è·å–æ‰€æœ‰å¤´
    
    # æ£€æŸ¥æ˜¯å¦æµå¼
    is_stream = request.stream
    
    # è·å–é¢å¤–å­—æ®µï¼ˆOpenAIRequest å…è®¸é¢å¤–å­—æ®µï¼‰
    custom_field = getattr(request, 'custom_field', None)
```

### å‘é€å“åº”

é€šè¿‡ Agent çš„ `stream` å¯¹è±¡å‘é€å“åº”ï¼š

```python
async def run(self, request: OpenAIRequest):
    user_query = request.get_user_query()
    
    # å‘é€æ€è€ƒè¿‡ç¨‹
    await self.stream.send("thinking", "æ­£åœ¨åˆ†æé—®é¢˜...")
    
    # å‘é€æ­£æ–‡
    await self.stream.send("text", "è¿™æ˜¯å›ç­”çš„å†…å®¹")
    
    # å‘é€ä»£ç 
    await self.stream.send("code", "print('Hello')")
    
    # ç»“æŸå“åº”
    await self.stream.stop()
```

---

## æµå¼å“åº”

### DataStreamer

Server ä½¿ç”¨ `DataStreamer` å¤„ç†æµå¼å“åº”ï¼š

```python
from alphora.server.stream_responser import DataStreamer

streamer = DataStreamer(timeout=300, model_name="MyModel")

# å‘é€æ•°æ®
await streamer.send_data(content_type="text", content="Hello")

# ç»“æŸæµ
await streamer.stop(stop_reason="stop")

# è·å–æµå¼å“åº”
response = streamer.start_streaming_openai()

# è·å–éæµå¼å“åº”
response = await streamer.start_non_streaming_openai()
```

### è¶…æ—¶å¤„ç†

é»˜è®¤è¶…æ—¶ 300 ç§’ï¼ˆ5 åˆ†é’Ÿï¼‰ã€‚è¶…æ—¶åè‡ªåŠ¨è¿”å› `finish_reason: "timeout"`ï¼š

```python
streamer = DataStreamer(timeout=60)  # 1 åˆ†é’Ÿè¶…æ—¶
```

---

## å®Œæ•´ç¤ºä¾‹

### åŸºç¡€ Agent API

```python
# my_agent.py
from alphora.agent import BaseAgent
from alphora.server.openai_request_body import OpenAIRequest

class MyAgent(BaseAgent):
    async def run(self, request: OpenAIRequest):
        """å¤„ç†ç”¨æˆ·è¯·æ±‚"""
        user_query = request.get_user_query()
        
        # è®°å½•åˆ°ä¼šè¯å†å²
        self.memory.add_user(user_query)
        
        # è°ƒç”¨ LLM
        result = await self.llm.acall(
            messages=self.memory.build_history()
        )
        
        # æµå¼è¾“å‡º
        async for chunk in result:
            await self.stream.send("text", chunk.content)
        
        # è®°å½•åŠ©æ‰‹å›å¤
        self.memory.add_assistant(result.response)
        
        # ç»“æŸ
        await self.stream.stop()
```

```python
# api_server.py
import uvicorn
from alphora.server.quick_api import publish_agent_api, APIPublisherConfig
from alphora.models.llms import OpenAILike
from my_agent import MyAgent

# åˆå§‹åŒ–
llm = OpenAILike(
    base_url="https://api.openai.com/v1",
    model_name="gpt-4",
    api_key="your-api-key"
)

agent = MyAgent(llm=llm)

# é…ç½®
config = APIPublisherConfig(
    path="/api/v1",
    memory_ttl=7200,        # 2 å°æ—¶
    max_memory_items=500,
    api_title="My Agent API",
    api_description="æ™ºèƒ½åŠ©æ‰‹ API æœåŠ¡"
)

# å‘å¸ƒ
app = publish_agent_api(agent=agent, method="run", config=config)

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

### å¸¦å·¥å…·çš„ Agent API

```python
from alphora.agent import BaseAgent
from alphora.tools import tool, ToolRegistry, ToolExecutor
from alphora.server.openai_request_body import OpenAIRequest

@tool
def search_web(query: str) -> str:
    """æœç´¢ç½‘ç»œ"""
    return f"æœç´¢ç»“æœ: {query}"

class ToolAgent(BaseAgent):
    def __init__(self, llm):
        super().__init__(llm=llm)
        self.registry = ToolRegistry()
        self.registry.register(search_web)
        self.executor = ToolExecutor(self.registry)
    
    async def run(self, request: OpenAIRequest):
        user_query = request.get_user_query()
        self.memory.add_user(user_query)
        
        # è°ƒç”¨ LLMï¼ˆå¸¦å·¥å…·ï¼‰
        result = await self.llm.acall(
            messages=self.memory.build_history(),
            tools=self.registry.get_all_tools()
        )
        
        # å¤„ç†å·¥å…·è°ƒç”¨
        if result.has_tool_calls:
            await self.stream.send("thinking", "æ­£åœ¨è°ƒç”¨å·¥å…·...")
            tool_results = await self.executor.execute(result.tool_calls)
            self.memory.add_assistant(result)
            self.memory.add_tool_result(tool_results)
            
            # ç»§ç»­å¯¹è¯
            final_result = await self.llm.acall(
                messages=self.memory.build_history()
            )
            async for chunk in final_result:
                await self.stream.send("text", chunk.content)
            self.memory.add_assistant(final_result)
        else:
            async for chunk in result:
                await self.stream.send("text", chunk.content)
            self.memory.add_assistant(result)
        
        await self.stream.stop()
```

### ç”Ÿäº§ç¯å¢ƒé…ç½®

```python
import logging
from alphora.server.quick_api import publish_agent_api, APIPublisherConfig

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

config = APIPublisherConfig(
    path="/api/v1",
    memory_ttl=3600,           # 1 å°æ—¶ä¼šè¯è¿‡æœŸ
    max_memory_items=10000,    # æ”¯æŒ 1 ä¸‡å¹¶å‘ä¼šè¯
    auto_clean_interval=300,   # 5 åˆ†é’Ÿæ¸…ç†ä¸€æ¬¡
    api_title="Production Agent API",
    api_description="ç”Ÿäº§ç¯å¢ƒæ™ºèƒ½åŠ©æ‰‹æœåŠ¡"
)

app = publish_agent_api(agent=agent, method="run", config=config)

# ä½¿ç”¨ Gunicorn éƒ¨ç½²
# gunicorn api_server:app -w 4 -k uvicorn.workers.UvicornWorker -b 0.0.0.0:8000
```

---

## API å‚è€ƒ

### publish_agent_api

```python
def publish_agent_api(
    agent: BaseAgent,
    method: str,
    config: Optional[APIPublisherConfig] = None
) -> FastAPI
```

| å‚æ•° | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `agent` | `BaseAgent` | Agent å®ä¾‹ |
| `method` | `str` | è¦æš´éœ²çš„å¼‚æ­¥æ–¹æ³•å |
| `config` | `APIPublisherConfig` | API é…ç½® |

### APIPublisherConfig

| å±æ€§ | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `path` | `str` | `"/alphadata"` | API åŸºç¡€è·¯å¾„ |
| `memory_ttl` | `int` | `3600` | ä¼šè¯è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ |
| `max_memory_items` | `int` | `1000` | æœ€å¤§ä¼šè¯æ•° |
| `auto_clean_interval` | `int` | `600` | æ¸…ç†é—´éš”ï¼ˆç§’ï¼‰ |
| `api_title` | `str` | `"Alphora Agent API Service"` | API æ ‡é¢˜ |
| `api_description` | `str` | `"Auto-generated API..."` | API æè¿° |

### OpenAIRequest

| å±æ€§/æ–¹æ³• | ç±»å‹ | è¯´æ˜ |
|----------|------|------|
| `model` | `str` | æ¨¡å‹åç§° |
| `messages` | `List[Message]` | æ¶ˆæ¯åˆ—è¡¨ |
| `stream` | `bool` | æ˜¯å¦æµå¼ |
| `session_id` | `str` | ä¼šè¯ ID |
| `user` | `str` | ç”¨æˆ·æ ‡è¯† |
| `get_user_query()` | `str` | è·å–ç”¨æˆ·è¾“å…¥ |
| `get_header(key)` | `Any` | è·å–è¯·æ±‚å¤´ |
| `set_headers(headers)` | `None` | è®¾ç½®è¯·æ±‚å¤´ |

### MemoryPool

| æ–¹æ³• | è¯´æ˜ |
|------|------|
| `get_or_create(session_id, memory_cls)` | è·å–æˆ–åˆ›å»ºä¼šè¯è®°å¿† |
| `clean_expired()` | æ¸…ç†è¿‡æœŸä¼šè¯ |
| `size` | å½“å‰ä¼šè¯æ•° |

### DataStreamer

| æ–¹æ³• | è¯´æ˜ |
|------|------|
| `send_data(content_type, content)` | å‘é€æ•°æ® |
| `stop(stop_reason)` | ç»“æŸæµ |
| `start_streaming_openai()` | è¿”å›æµå¼å“åº” |
| `start_non_streaming_openai()` | è¿”å›éæµå¼å“åº” |

### å¼‚å¸¸ç±»

| å¼‚å¸¸ | è¯´æ˜ |
|------|------|
| `AgentValidationError` | Agent æ ¡éªŒå¤±è´¥ï¼ˆç±»å‹é”™è¯¯ã€æ–¹æ³•ä¸å­˜åœ¨ç­‰ï¼‰ |
